# Multimodal AI (멀티모달 AI)

## 1. 개요 (Overview)
Multimodal AI(멀티모달 AI)는 텍스트, 이미지, 오디오, 비디오 등 서로 다른 형태(Modality)의 데이터를 함께 처리하고 이해하는 AI 기술입니다. 인간이 시각, 청각 등 다양한 감각을 통해 세상을 이해하는 것과 같습니다.

## 2. 필요성
단일 모달리티(예: 텍스트만 처리)로는 정보의 한계가 있습니다. 예를 들어, "사과"라는 단어를 이해하는 것보다 사과 사진을 보고 "사과"라고 인식하는 것이 더 풍부한 정보를 담고 있습니다.

## 3. 주요 모델 (Key Models)

### 3.1. CLIP (Contrastive Language-Image Pre-training)
OpenAI가 개발한 모델로, 이미지와 텍스트 쌍을 대량으로 학습하여 이미지와 텍스트 사이의 연관성을 이해합니다. "강아지 사진"과 "강아지"라는 텍스트가 같은 의미임을 학습합니다.

### 3.2. Flamingo
DeepMind가 개발한 시각적 언어 모델(VLM)로, 이미지를 보고 질문에 답하거나 대화를 나눌 수 있습니다.

### 3.3. GPT-4V / Gemini
최신 LLM들은 텍스트뿐만 아니라 이미지를 입력으로 받아 분석하고 추론하는 멀티모달 능력을 갖추고 있습니다.
