# AI Ethics (AI 윤리)

## 1. 개요 (Overview)
AI 기술이 발전함에 따라 기술적 성능뿐만 아니라 윤리적, 사회적 영향에 대한 고려가 중요해지고 있습니다. AI Ethics(AI 윤리)는 AI가 인간에게 해를 끼치지 않고 공정하고 안전하게 사용되도록 하는 가이드라인입니다.

## 2. 주요 이슈 (Key Issues)

### 2.1. Bias & Fairness (편향과 공정성)
AI 모델은 학습 데이터에 포함된 편향(성별, 인종, 지역 등)을 그대로 학습하거나 증폭시킬 수 있습니다.
- **예시**: 채용 AI가 특정 성별이나 인종에게 불리한 점수를 주는 경우.
- **대응**: 학습 데이터의 균형을 맞추고, 모델의 공정성을 평가하는 지표를 도입해야 합니다.

### 2.2. Explainability (설명 가능성, XAI)
[Deep Learning](./DLBasic.md) 모델은 내부 동작을 이해하기 어려운 "블랙박스(Black Box)"인 경우가 많습니다.
- **XAI (Explainable AI)**: AI가 왜 그런 결정을 내렸는지 사람이 이해할 수 있도록 설명하는 기술입니다. 의료나 금융처럼 신뢰가 중요한 분야에서 필수적입니다.

### 2.3. Safety & Alignment (안전과 정렬)
AI의 목표가 인간의 가치관과 일치하도록 만드는 것입니다.
- **AI Alignment**: AI가 인간이 의도한 대로, 유익한 방향으로 행동하도록 조정하는 연구입니다.

### 2.4. Deepfake & Misinformation (딥페이크와 가짜 정보)
[Generative AI](./GenerativeAI.md)의 발전으로 진짜와 구별하기 힘든 가짜 이미지나 목소리를 생성할 수 있게 되었습니다. 이를 악용한 범죄나 가짜 뉴스 유포에 대한 대응이 필요합니다.

## 3. 결론
AI 개발자는 단순히 성능 좋은 모델을 만드는 것을 넘어, 그 모델이 사회에 미칠 영향까지 책임감 있게 고려해야 합니다.
