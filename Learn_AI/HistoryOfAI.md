# History of AI (AI의 역사)

## 1. 개요 (Overview)

인공지능(AI)의 역사는 **기대와 실망이 반복**되는 과정이었습니다. 흔히 "AI의 봄"과 "AI의 겨울"이라 불리는 이 사이클을 이해하면, 현재의 AI 붐이 어떤 맥락에서 왔는지, 그리고 앞으로 어디로 갈지 가늠할 수 있습니다.

### AI 역사를 배우는 이유
- 같은 실수를 반복하지 않기 위해
- 현재 기술의 한계와 가능성을 객관적으로 평가하기 위해
- 미래 방향을 예측하기 위해

## 2. 주요 흐름 (Timeline)

### 2.1. 태동기 (1950년대) - AI의 탄생

#### 튜링 테스트 (1950)
**Alan Turing**은 "기계가 생각할 수 있는가?"라는 질문을 던지며 **튜링 테스트(Turing Test)**를 제안했습니다.

**튜링 테스트란?**
- 사람이 기계와 대화를 나눴을 때, 그것이 기계인지 인간인지 구별하지 못하면 그 기계는 "지능이 있다"고 볼 수 있다는 개념
- 현대의 ChatGPT, Claude 같은 대화형 AI의 철학적 기원

#### AI라는 용어의 탄생 (1956)
- **다트머스 회의(Dartmouth Conference)**: 존 매카시(John McCarthy) 등이 "Artificial Intelligence"라는 용어를 처음 사용
- "10년 안에 기계가 인간처럼 생각할 것"이라는 낙관적 전망

#### Perceptron (1958)
- Frank Rosenblatt이 개발한 **최초의 인공 신경망** 모델
- 인간 뇌의 뉴런을 모방하여 간단한 패턴 인식 가능
- 당시에는 "곧 인간을 능가할 것"이라는 과도한 기대

### 2.2. 첫 번째 AI 겨울 (1970년대) - 환멸의 시기

#### 왜 겨울이 왔는가?
- **Perceptron의 한계 발견**: Marvin Minsky와 Seymour Papert가 Perceptron이 **XOR 문제** 같은 간단한 문제조차 해결 못한다는 것을 증명
- 과도한 기대에 비해 실제 성과는 미미
- 연구 자금 지원이 대폭 감소

**XOR 문제란?**
```
입력 A | 입력 B | 출력
   0   |   0    |  0
   0   |   1    |  1
   1   |   0    |  1
   1   |   1    |  0
```
단층 Perceptron으로는 이런 비선형 관계를 학습할 수 없었습니다.

**교훈**: 기술의 한계를 정확히 파악하지 못한 과대 광고는 역효과를 낳습니다.

### 2.3. 지식 기반 시스템 (1980년대) - 부분적 부활

#### Expert System (전문가 시스템)의 등장
인간 전문가의 지식을 **규칙(If-Then Rule)** 형태로 컴퓨터에 입력하여 문제를 해결하려 했습니다.

**예시**: MYCIN (의료 진단 시스템)
```
IF 환자가 발열이 있고
AND 혈액 배양 검사 결과가 양성이면
THEN 세균 감염 가능성 90%
```

#### 왜 다시 실패했는가? (두 번째 AI 겨울)
- **확장성 문제**: 규칙이 수천 개가 되면 관리 불가능
- **예외 처리 불가**: 세상의 모든 상황을 규칙으로 표현할 수 없음
- **유지보수 어려움**: 규칙 하나 바뀌면 전체 시스템이 영향받음
- **상식 부족**: "문을 열고 들어간다"는 간단한 상식조차 규칙으로 만들기 어려움

**교훈**: 지식을 수동으로 입력하는 접근법의 한계 → 데이터로부터 **자동으로 학습**하는 방법 필요

### 2.4. 머신러닝의 부상 (1990년대 ~ 2000년대) - 패러다임 전환

#### 핵심 변화
"규칙을 직접 코딩"하는 방식에서 **"데이터로부터 학습"**하는 [Machine Learning](./MLBasic.md) 방식으로 전환

#### 주요 발전
- **SVM (Support Vector Machine)**: 고차원 데이터의 분류에 탁월
- **Random Forest**: 여러 개의 결정 트리를 조합한 앙상블 방법
- **통계적 학습 이론**: 과적합 방지, 일반화 성능 향상
- **실용적 성과**: 스팸 필터, 추천 시스템 등 실생활에 적용

#### 왜 성공했는가?
- **인터넷 보급**: 방대한 데이터 수집 가능
- **컴퓨팅 파워 향상**: 복잡한 계산이 가능해짐
- **현실적 목표**: "인간 수준 AI" 대신 "특정 작업을 잘하는 AI"에 집중

### 2.5. 딥러닝 혁명 (2010년대) - AI 르네상스

#### ImageNet Challenge (2012) - 역사적 전환점
- AlexNet이 기존 방법을 **압도적 차이**로 제치고 우승
- **딥러닝(Deep Learning)**의 우수성이 입증됨
- GPU를 활용한 병렬 연산으로 학습 시간 대폭 단축

**성능 비교**:
- 기존 최고 기법: 약 26% 오류율
- AlexNet: 약 16% 오류율 (거의 10% 차이!)

#### 딥러닝 폭발적 성장 (2012~2016)
- **컴퓨터 비전**: 이미지 인식, 객체 탐지, 얼굴 인식
- **음성 인식**: Siri, 구글 어시스턴트
- **자연어 처리**: 기계 번역 품질 혁신적 개선

#### AlphaGo (2016) - 세상을 놀라게 하다
구글 딥마인드의 AlphaGo가 이세돌 9단을 4:1로 이기며 세계에 충격을 줌

**왜 중요한가?**
- 바둑은 경우의 수가 우주의 원자 개수보다 많은 복잡한 게임
- [Reinforcement Learning (강화 학습)](./ReinforcementLearning.md)의 가능성 입증
- "AI가 인간의 직관과 창의성까지 넘볼 수 있다"는 인식 확산

### 2.6. Transformer와 대규모 언어 모델 (2017~2020) - NLP의 혁명

#### Transformer (2017) - 구조적 혁신
구글이 발표한 "Attention Is All You Need" 논문

**혁신적 이유**:
- 기존 RNN 방식의 순차 처리 한계 극복
- **병렬 처리 가능** → 학습 속도 대폭 향상
- **Attention Mechanism**: 문맥 전체를 고려한 이해

#### BERT (2018) - 언어 이해의 혁명
구글의 BERT가 자연어 이해 과제에서 인간 수준 달성

#### GPT 시리즈 - 언어 생성의 진화
- GPT-1 (2018): 개념 증명
- GPT-2 (2019): "너무 위험해서 공개 못하겠다" (나중에 공개됨)
- GPT-3 (2020): 1750억 개 파라미터, 놀라운 텍스트 생성 능력

### 2.7. 생성형 AI 시대 (2020년대 ~ 현재) - AI의 민주화

#### ChatGPT (2022.11) - 대중화의 시작
- 출시 **5일 만에 100만 명** 사용자 돌파 (역대 최단 기록)
- AI가 일반 대중의 일상에 진입
- "AI를 사용할 줄 아는 것"이 새로운 문해력이 됨

#### Multimodal AI (2023~)
- **GPT-4**: 텍스트와 이미지를 모두 이해
- **GPT-4o**: 텍스트, 이미지, 음성을 실시간으로 처리
- **Gemini**: 구글의 멀티모달 AI

#### 생성형 AI 확산
- **이미지**: DALL-E 3, Midjourney, Stable Diffusion
- **동영상**: Sora (OpenAI), Runway
- **음성**: ElevenLabs, OpenAI TTS
- **코딩**: GitHub Copilot, Cursor

#### 현재의 트렌드 (2024~)
- **더 큰 모델 vs 더 효율적인 모델**: 파라미터 수 경쟁에서 효율성 경쟁으로
- **AI Agent**: 단순 대화를 넘어 작업 자동 수행
- **Reasoning Models**: OpenAI o1, o3 같은 추론 특화 모델
- **Edge AI**: 클라우드가 아닌 기기에서 직접 실행

## 3. AI 역사의 패턴과 교훈

### 반복되는 사이클
```
과도한 기대 → 기술적 한계 부딪힘 → 환멸과 겨울 → 새로운 돌파구 → 다시 기대
```

### 주요 교훈

#### 1. 데이터의 중요성
- 1980년대: 규칙 기반 (실패)
- 2010년대: 대규모 데이터 기반 학습 (성공)

#### 2. 컴퓨팅 파워의 역할
- 1970년대: Perceptron은 이론적으로는 좋았지만 연산 능력 부족
- 2012년 이후: GPU의 발전으로 딥러닝 실용화

#### 3. 현실적 목표 설정
- 실패한 시기: "곧 인간 수준 AI"
- 성공한 시기: "특정 작업에서 인간을 능가"

#### 4. 과대 광고의 위험
- 근거 없는 낙관은 투자 감소로 이어짐
- 기술의 한계를 정직하게 인정하는 것이 장기적으로 유리

## 4. 미래 전망

### 다음은 무엇인가?

#### 가능성 있는 방향
- **AGI (Artificial General Intelligence)**: 범용 인공지능 개발 시도
- **더 효율적인 학습**: 적은 데이터로 학습 ([Few-Shot Learning](./FewShotLearning.md))
- **AI 안전성**: 통제 가능하고 윤리적인 AI ([AI Ethics](./AIEthics.md))
- **AI + 과학**: 신약 개발, 기후 모델링, 핵융합 등

#### 우려사항
- 일자리 대체
- 편향과 차별 증폭
- 에너지 소비 증가
- 통제 불가능한 AI (SF가 아닌 실제 연구 주제)

### 또 다른 AI 겨울이 올까?
- **가능성**: 현재 투자 대비 실질적 가치 창출 부족 시
- **방어책**: 과대 광고 자제, 실용적 응용에 집중, 한계 인정

## 5. 관련 문서
- [Artificial Intelligence (인공지능)](./ArtificialIntelligence.md) - AI의 기본 개념
- [AI Ethics (AI 윤리)](./AIEthics.md) - AI 발전과 함께 고려해야 할 윤리
- [Machine Learning Basics (머신러닝 기초)](./MLBasic.md) - 현대 AI의 핵심
- [Deep Learning Basics (딥러닝 기초)](./DLBasic.md) - 2010년대 혁명의 주역
- [Transformer (트랜스포머)](./Transformer.md) - 현대 AI의 핵심 아키텍처
