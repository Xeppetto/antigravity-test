# Transfer Learning (전이 학습)

## 1. 개요 (Overview)
Transfer Learning(전이 학습)은 방대한 데이터로 미리 학습된(Pre-trained) 모델의 지식을 가져와, 데이터가 적거나 유사한 다른 문제를 해결하는 데 재사용하는 기법입니다. "거인의 어깨 위에 올라타는 것"과 같습니다.

## 2. 왜 사용하는가?
- **데이터 부족 해결**: 처음부터 학습시키려면 수만 장의 이미지가 필요하지만, 전이 학습을 쓰면 수백 장으로도 좋은 성능을 낼 수 있습니다.
- **학습 속도 향상**: 이미 특징을 추출하는 법을 알고 있는 모델을 사용하므로, 수렴 속도가 훨씬 빠릅니다.
- **성능 향상**: 대규모 데이터셋(ImageNet 등)에서 학습된 풍부한 표현력을 활용할 수 있습니다.

## 3. 방법 (Methods)

### 3.1. Feature Extraction (특징 추출)
사전 학습된 모델의 앞부분(Convolutional Base 등)은 고정(Freeze)하고, 마지막 분류기(Classifier)만 새로운 문제에 맞게 교체하여 학습시킵니다.

### 3.2. Fine-tuning (미세 조정)
모델의 일부 또는 전체 층의 가중치 규제를 풀고(Unfreeze), 새로운 데이터에 대해 아주 낮은 학습률로 다시 학습시킵니다. 모델이 새로운 데이터의 세밀한 특징까지 학습하도록 돕습니다.

## 4. 활용 사례
- **Computer Vision**: ImageNet으로 학습된 ResNet 등을 가져와 의료 영상 분석이나 불량 검출에 사용.
- **NLP**: [Transformer](./Transformer.md) 기반의 BERT, GPT 등을 가져와 감성 분석이나 챗봇 개발에 사용.
