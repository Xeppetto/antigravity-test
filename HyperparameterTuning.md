# Hyperparameter Tuning (하이퍼파라미터 튜닝)

## 1. 개요 (Overview)
모델이 스스로 학습하는 파라미터(가중치)와 달리, 사람이 학습 전에 미리 설정해주어야 하는 값들을 **Hyperparameter(하이퍼파라미터)**라고 합니다. 이 값들을 최적의 조합으로 설정하는 과정을 Hyperparameter Tuning이라고 합니다.

## 2. 주요 하이퍼파라미터 (Key Hyperparameters)
- **Learning Rate (학습률)**: 한 번의 업데이트로 가중치를 얼마나 바꿀지 결정합니다. 너무 크면 발산하고, 너무 작으면 학습이 너무 느립니다.
- **Batch Size (배치 크기)**: 한 번에 학습할 데이터의 개수입니다.
- **Epochs (에폭)**: 전체 데이터를 몇 번 반복해서 학습할지 결정합니다.
- **Hidden Units / Layers**: 신경망의 층 수와 각 층의 뉴런 개수입니다.

## 3. 튜닝 방법 (Methods)

### 3.1. Grid Search
가능한 모든 조합을 표(Grid)처럼 만들어서 하나씩 다 시도해보는 방법입니다. 확실하지만 시간이 매우 오래 걸립니다.

### 3.2. Random Search
설정 범위 내에서 무작위로 값을 뽑아서 시도해보는 방법입니다. Grid Search보다 효율적이며 의외로 좋은 결과를 낼 때가 많습니다.

### 3.3. Bayesian Optimization
이전의 시도 결과를 바탕으로, 더 좋은 성능을 낼 확률이 높은 값을 똑똑하게 추정하여 시도하는 방법입니다.
